{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6be58f9",
   "metadata": {},
   "source": [
    "# librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed2aa4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools # para generar combinarion de elemntos de una lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c698c75",
   "metadata": {},
   "source": [
    "# ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a6677",
   "metadata": {},
   "source": [
    "CONCEPTOS PARA EL ALGORITMO APRIORI\n",
    "\n",
    "SUPPORT = cantidad item A / NRO de itemsets\n",
    "\n",
    "CONFIDENCE(A -> B)\n",
    "CONFIDENCE = cantidad de A y B / cantidad item A \n",
    "\n",
    "LIFT(A -> B)\n",
    "LIFT = confidence(A -> B) / suport(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04539a",
   "metadata": {},
   "source": [
    "# cargar el dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1758136",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/Users/blablabla/usuario_alojado/SEMESTRE_II_2021/Mineria-de-datos/Actividad03/spotify.npy', allow_pickle=True)\n",
    "data1 = data.item(0) # contiene los itemsets en una diccionario {0: [itemset1], 1: [itemset2],...}\n",
    "\n",
    "# dataset de prueba para testear los modulos individuales\n",
    "dataTest = {0:['Pan','Leche','Pañales'],\n",
    "           1:['Pan','Pañales','Cerveza','Huevos'],\n",
    "           2:['Leche','Pañales','Cerveza','Refresco','Café'],\n",
    "           3:['Pan','Leche','Pañales','Cerveza'],\n",
    "           4:['Pan','Refresco','Leche','Pañales']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f049b9d",
   "metadata": {},
   "source": [
    "### modulo para genera nuevos super ItemSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcc26487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidateGet(itemSetsFrecuentes, length): #retorna una lista con los nuevos superItemSets \n",
    "    superItemSets = []\n",
    "    for index, itemSet in enumerate(itemSetsFrecuentes): # rrecorremos cada itemset\n",
    "        for j in range(index+1,len(itemSetsFrecuentes)): # rrecorre apartir del siguiente itemset \n",
    "            union = np.append(itemSet,itemSetsFrecuentes[j]) # mescla el itemset con todos los itemset que estan delante \n",
    "            union = list(set(union)) # elimina elementos repetidos\n",
    "            union = sorted(union) # ordena los elementos\n",
    "            #print(union)\n",
    "            if len(union) == length and union not in superItemSets: # filtra los itemsets nuevos que complan con length\n",
    "                superItemSets.append(union)\n",
    "    return superItemSets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9134ca2",
   "metadata": {},
   "source": [
    "### modulo para podar los superItemSets que contengan subItemSet no frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "942cff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidatePrune( newItemSets, itemSetsFrecuentes): # retorna un arreglo\n",
    "    pruneList = []\n",
    "    for itemSet in newItemSets: # rrecorremos cada itemset \n",
    "        cont = 0 # para validar que todos sus subItemSet sean frecuentes\n",
    "        # combinar los elementos del itemset actual en grupos de tamaños len(itemSet)-1 (una unidad menor que el itemset)\n",
    "        # para verificar que sus sub grupos sean frecuentes\n",
    "        combinaciones = list(itertools.combinations(itemSet,len(itemSet)-1)) \n",
    "        #print(len(combinaciones), combinaciones)\n",
    "        for element in combinaciones: # contamos cuantos de esas combinaciones estan en itemSetsFrecuentes \n",
    "            #print(element, list(element))\n",
    "            if list(element) in itemSetsFrecuentes:\n",
    "                cont += 1\n",
    "        #print(cont)\n",
    "        if cont == len(combinaciones): # verificamos que todas las combinaciones esten dentro de itemSetsFrecuentes\n",
    "            pruneList.append(itemSet)\n",
    "    return pruneList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75514f05",
   "metadata": {},
   "source": [
    "### modulo para verificar si un subItemSet se encuentra dentro de un ItemSet original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2813837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(Candidatos, itemSetOriginal): # retorna una lista de los candidatos que se encuentran en el ItemSetOriginal\n",
    "    encontrados = []\n",
    "    for candidato in Candidatos: # recorre todos los candidatos\n",
    "        contador = 0 # para validar que se encontraron todos los items dentro del itemSetOriginal\n",
    "        for item in candidato: # recorre todos los elementos del candidato\n",
    "            if (item in itemSetOriginal): \n",
    "                contador += 1 # suma 1 si el item se encuentra dentro del itemSet original\n",
    "        if contador == len(candidato): # comprueba que todos los items del candidato estan dentro del itemSet original\n",
    "            encontrados.append(candidato)\n",
    "    return encontrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224356e",
   "metadata": {},
   "source": [
    "# modulo para extraer los itemSets frecuentes del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d542459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_itemsets(playlists, min_support): # min_supoort en el rango de [0,1]\n",
    "    # VARIABLES \n",
    "    nroItemSets = len(playlists) # SUPPORT = cantidadItem / nroItemSets\n",
    "    itemSetsFrecuentes = [] # lista que almacena los itemsets frecuentes \n",
    "    listSupport = [] # Lista que almacena los suports de los itemsets frecuentes\n",
    "    \n",
    "    # Encontrar los 1-itemsets frecuentes\n",
    "    frecuencias = {} # acumula las item junsto a su nro de veces itemsets en los que aparece\n",
    "    musicas = [] # guarda los items individuales\n",
    "    noRepetidos = [] # es un filtro de la anterior lista, lista sin repetidos\n",
    "    frecuentes = [] # \n",
    "    for i in playlists:\n",
    "        for j in playlists[i]:\n",
    "            musicas.append(j)\n",
    "    noRepetidos = sorted(set(musicas))\n",
    "    #print(noRepetidos)\n",
    "    for i in noRepetidos:\n",
    "        frecuencias[i] = musicas.count(i)\n",
    "    for i in frecuencias:\n",
    "        if frecuencias[i]/nroItemSets >= min_support:\n",
    "            frecuentes.append([i])\n",
    "            itemSetsFrecuentes.append([i])\n",
    "            listSupport.append(frecuencias[i]/nroItemSets)\n",
    "    # Bucle para encontrar n-itemsets frecuentes mientras existan.\n",
    "    #VARIABLES\n",
    "    print(frecuentes)\n",
    "    k = 1\n",
    "    FK = [] # lista de itemsets frecuentes de K-items \n",
    "    while (len(frecuentes) > 1):\n",
    "        k += 1\n",
    "        FK = candidateGet(frecuentes,k) # generar K-itemsets candidatos \n",
    "        FK = candidatePrune(FK, frecuentes) # podar candidatos que tengan sub-itemsets no frecuentes\n",
    "        SUPPORT = [0]*len(FK) # creamos un arreglo que va a almacenar los support\n",
    "        #print(playlists)\n",
    "        for playlist in playlists: # bucle para calcular su SUPPORT y definir los nuevos K-itemsets frecuentes\n",
    "            #print(playlist)\n",
    "            encontrados = subset(FK, playlists[playlist])  # revisar que supergrupos de FK estan en la playlist\n",
    "            for encontrado in encontrados:\n",
    "                SUPPORT[FK.index(encontrado)] += 1\n",
    "        frecuentes = []\n",
    "        for index,candidato in enumerate(FK):\n",
    "            #print(candidato)\n",
    "            #print(SUPPORT[index]/nroItemSets)\n",
    "            if (SUPPORT[index]/nroItemSets >= min_support):\n",
    "                itemSetsFrecuentes.append(candidato)\n",
    "                listSupport.append(SUPPORT[index]/nroItemSets)\n",
    "                frecuentes.append(candidato)\n",
    "    return itemSetsFrecuentes, listSupport\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2709ca",
   "metadata": {},
   "source": [
    "### generación de los itemsets frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuentes, Supports = get_frequent_itemsets(data1,0.05)\n",
    "print(frecuentes)\n",
    "print(Supports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a71d96",
   "metadata": {},
   "source": [
    "### modulo para generar nuevas reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesCandidateGen( rules, lengt):\n",
    "    superItemSets = []\n",
    "    for index, itemSet in enumerate(rules): # recorre todos las reglas actuales\n",
    "        for j in range(index,len(rules)): # recorre las reglas desde la siguiente posicion\n",
    "            union = np.append(itemSet,rules[j]) # une los elementos de la Regla actual con una de las reglas siguientes\n",
    "            union = set(union) # se eliminan elementos repetidos\n",
    "            union = sorted(union) # se ordenan los elementos\n",
    "            if len(union) == lengt and union not in superItemSets: # se verifica que la longitud cumpla con lengt\n",
    "                superItemSets.append(union)\n",
    "    return superItemSets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fdb7fd",
   "metadata": {},
   "source": [
    "### modulo para podar reglas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20d0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesCandidatePrune( candidatos, subCandidatos):\n",
    "    candidatePrune = []\n",
    "    for candidato in candidatos: # recorre todos los candidatos\n",
    "        cont = 0 # contador para verificar que todos los subConjuntos de candidato sean reglas que superan el confidence\n",
    "        if (len(candidato)-1 == 0): # en caso de que las reglas actuales (candidatos) tengan un solo elementos como antecedente\n",
    "            subCombinaciones = candidatos\n",
    "        else: # en caso de que las reglas actules (candidatos) tengan mas de 1 elemento como antecedente\n",
    "            subCombinaciones = list(itertools.combinations(candidato, len(candidato)-1))\n",
    "        for item in subCombinaciones: # contamos cuantos de sus subconjuntos son reglas que superan el confidence\n",
    "            if list(item) in subCandidatos:\n",
    "                cont += 1\n",
    "        if cont == len(subCombinaciones): # ferificamos que todos sus subconjutnos sean reglas validas\n",
    "            candidatePrune.append(candidato)\n",
    "    return candidatePrune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e40814",
   "metadata": {},
   "source": [
    "# modulo para generar las reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa438251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(frequent_itemsets, supports, confidence = 0, lift = 0):\n",
    "    # VARIABLES\n",
    "    rules = [] # almacena las reglas que superen el confidence y ordenadas por el lift\n",
    "    _confi = [] # almacena el confidence de las reglas\n",
    "    _lift = [] # almacena el lift de las reglas\n",
    "    listPoda = [] # almacena los subconjuntos que no superen el confidence\n",
    "    \n",
    "    #\n",
    "    for index, itemset in enumerate(frequent_itemsets):\n",
    "        # convertimos los elementos de itemset en listas\n",
    "        newItemset = [[i] for i in itemset]\n",
    "        k = len(newItemset) # tamaño del itemset\n",
    "        m = 1 # tamaño inicial del consecuente de la regla\n",
    "        H = newItemset # inicializacion de la lista que almacenara las reglas generadas de itemset \n",
    "        #print(k, itemset)\n",
    "        while k > m:\n",
    "            candidatos = rulesCandidateGen(H, m) # generamos nuevas reglas \n",
    "            candidatos = rulesCandidatePrune( candidatos, H) # podamos algunas reglas\n",
    "            H = []\n",
    "            for candidato in candidatos:\n",
    "                _support = frequent_itemsets.index(candidato) # calculamos el indice del support para el candidato\n",
    "                conf = supports[index] / supports[_support]\n",
    "                if conf >= confidence:\n",
    "                    # generar la regla que tiene la forma de [[antecedente],[precedente]]\n",
    "                    antecedente = candidato\n",
    "                    precedente  = list(sorted(set(itemset).difference(set(candidato))))\n",
    "                    #print(\"precedente: \",precedente)\n",
    "                    rules.append([antecedente,precedente])\n",
    "                    _confi.append(conf)\n",
    "                    # Calcular el lift\n",
    "                    lift = conf / supports[frequent_itemsets.index(precedente)]\n",
    "                    _lift.append(lift)\n",
    "                    H.append(candidato)\n",
    "            m += 1\n",
    "    \n",
    "    return rules, _lift\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8273e78",
   "metadata": {},
   "source": [
    "### generacion de reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas, listLift = generate_association_rules(frecuentes, Supports, confidence = 0.5, lift = 1.2)\n",
    "for index, regla in enumerate(reglas):\n",
    "    print(regla, listLift[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
